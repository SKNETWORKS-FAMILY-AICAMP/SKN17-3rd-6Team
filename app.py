import os
import streamlit as st
import json
import torch
from datetime import datetime
from dotenv import load_dotenv
from langchain.llms import Ollama
from langchain.vectorstores import FAISS
from langchain.output_parsers import ResponseSchema
from langchain_core.output_parsers import StrOutputParser
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate
from collections import defaultdict
from langchain_huggingface import HuggingFaceEmbeddings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì „ì—­ ë³€ìˆ˜
VECTOR_STORE = None
CHAT_MODEL = None
CHAIN = None
CAR_DATA = None

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ”§ AutoFix ìë™ì°¨ ì§„ë‹¨ì„¼í„°",
    page_icon="ğŸ”§",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main {
        padding: 2rem;
    }
    
    .header-container {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        border: 3px solid #ffd700;
        box-shadow: 0 8px 25px rgba(0,0,0,0.3);
    }
    
    .chat-message {
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 15px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    .user-message {
        background: linear-gradient(135deg, #007bff, #0056b3);
        color: white;
        margin-left: 20%;
        border-bottom-right-radius: 5px;
    }
    
    .bot-message {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        color: #333;
        margin-right: 20%;
        border-left: 4px solid #ffd700;
        border-bottom-left-radius: 5px;
    }
    
    .diagnostic-card {
        background: linear-gradient(45deg, #28a745, #20c997);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 5px solid #ffd700;
        box-shadow: 0 4px 15px rgba(40, 167, 69, 0.3);
    }
    
    .car-info-box {
        background: linear-gradient(135deg, #17a2b8, #138496);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
    }
    
    .tool-icons {
        font-size: 2rem;
        margin: 1rem 0;
    }
    
    .loading-spinner {
        text-align: center;
        padding: 2rem;
        color: #007bff;
    }
</style>
""", unsafe_allow_html=True)


# ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤
store = {}

class InMemoryHistory(BaseChatMessageHistory):
    def __init__(self):
        super().__init__()
        self.messages = []

    def add_messages(self, messages):
        self.messages.extend(messages)

    def clear(self):
        self.messages = []

    def __repr__(self):
        return str(self.messages)

def get_by_session_id(session_id):
    if session_id not in store:
        store[session_id] = InMemoryHistory()
    return store[session_id]


# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
def initialize_rag_system():
    db_path = './database/final_db'
    device = "cuda" if torch.cuda.is_available() else "cpu"
        
    # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_model = HuggingFaceEmbeddings(
        model_name="dragonkue/snowflake-arctic-embed-l-v2.0-ko",
        model_kwargs={"device": "cpu"}
    )
        
    vector_store = FAISS.load_local(
        db_path, 
        embedding_model, 
        allow_dangerous_deserialization=True
    )

    model_name = 'EEVE-Korean-10.8B:latest'
    chat_model = Ollama(model=model_name)

    # ì²´ì¸ ìƒì„±
    chain = make_chain(chat_model)

    return vector_store, chain
    


# ì°¨ëŸ‰ ë°ì´í„° ì¶”ì¶œ
def extract_car_data_from_db(vector_store):
    car_data = defaultdict(lambda: defaultdict(lambda: {"engines": set()}))
    
    try:
        all_docs = vector_store.similarity_search("", k=3000)
        
        for doc in all_docs:
            metadata = dict(doc.metadata) if doc.metadata else {}

            model_type = metadata.get('type', '').strip()
            model = metadata.get('car_type', '').strip()
            engine = metadata.get('engine_type', '').strip()
            
            if model_type and model:
                if engine:
                    car_data[model_type][model]["engines"].add(engine)
        
        # Setì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        for model_type in car_data:
            for model in car_data[model_type]:
                car_data[model_type][model]["engines"] = sorted(list(car_data[model_type][model]["engines"]))
                
        return dict(car_data)

    except Exception as e:
        st.error(f"ì°¨ëŸ‰ ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {}


# ì²´ì¸ ìƒì„±
def make_chain(model):
    instruction = """
    ë‹¹ì‹ ì€ ìë™ì°¨ ì „ë¬¸ê°€ ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì§€ì¹¨ì„ ì°¸ê³ í•˜ì—¬ ìµœì ì˜ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
    - ì§ˆë¬¸ì´ ì „ë¬¸ ì§€ì‹ ê´€ë ¨ì´ë©´ ì œê³µëœ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
    - ì¡ë‹´ì´ë‚˜ ì¼ë°˜ ì¸ì‚¬ ì§ˆë¬¸ì´ë©´ ë¬¸ì„œë¥¼ ë¬´ì‹œí•˜ê³  ì§ˆë¬¸ë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
    - ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ í•˜ë©°, ì˜ì–´ë¥¼ ì ˆëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    - ì ˆëŒ€ ëŒ€ë‹µì— í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì´ë‚˜ ì‚¬ìš©ì ì§ˆë¬¸, ì°¸ê³  ë¬¸ì„œ ë“±ì˜ ë‚´ìš©ì„ í¬í•¨ì‹œí‚¤ì§€ ë§ˆì„¸ìš”.
    - ë§ˆí¬ë‹¤ìš´ í‘œë‚˜ ###, ---, *** ê°™ì€ í‘œì‹œ ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    - ìš´ì „ìë‚˜ ì¼ë°˜ ë…ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”
    """

    parser = StrOutputParser()
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(instruction),
        MessagesPlaceholder(variable_name='history'),
        HumanMessagePromptTemplate.from_template(
            "ì‚¬ìš©ì ì§ˆë¬¸: {query}\n\n"
            "ì°¸ê³  ë¬¸ì„œ:\n{content}\n\n"
            "ìœ„ì˜ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ì—¬ ì˜¤ì§ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ë§Œ ìƒì„±í•´ì•¼ í•´."
        )
    ])
    
    chain = prompt | model | parser

    chain_with_history = RunnableWithMessageHistory(
        chain,
        get_session_history=get_by_session_id,
        input_messages_key='query',
        history_messages_key='history'
    )

    return chain_with_history


# í•„í„° ìƒì„±
def make_filter(filter: dict):
    if any(list(filter.values())):
        main_filter = filter.copy()
    else:
        main_filter = None

    sub_filter = {k: {"$eq": "any"} for k in filter.keys()}

    return main_filter, sub_filter


# ë¬¸ì„œ ê²€ìƒ‰
def search_documents(query, car_info, vector_store, k=5):
    main_filter, sub_filter = make_filter(car_info)
    
    if main_filter:
        main_docs = vector_store.similarity_search(query, k=1, filter=main_filter)
        unique_main_docs = list({doc.page_content: doc for doc in main_docs}.values())
    else:
        unique_main_docs = []
    
    sub_docs = vector_store.similarity_search(query, k=1)
    unique_sub_docs = list({doc.page_content: doc for doc in sub_docs}.values())
    all_docs = unique_main_docs + unique_sub_docs

    context_text = '\n'.join([doc.page_content for doc in all_docs])

    return context_text


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    if 'page' not in st.session_state:
        st.session_state.page = 'setup'
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'car_info' not in st.session_state:
        st.session_state.car_info = {}


# ì°¨ëŸ‰ ì„¤ì • í˜ì´ì§€
def setup_page(car_data=None):
    st.markdown("""
    <div class="header-container">
        <h1>ğŸ”§ AutoFix ìë™ì°¨ ì§„ë‹¨ì„¼í„° ğŸ”§</h1>
        <div class="tool-icons">ğŸš— ğŸ” âš™ï¸ ğŸ› ï¸</div>
        <h3>ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ ì°¨ëŸ‰ ì •ë³´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”</h3>
        <p>â€» ì°¨ì¢…ì„ ëª¨ë¥´ì‹œë©´ ë¸Œëœë“œë§Œ ì„ íƒí•˜ê³  ì§„í–‰í•˜ì…”ë„ ë©ë‹ˆë‹¤</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸš— ìë™ì°¨ ë¸Œëœë“œ")
        brand = ["ë¸Œëœë“œ ì„ íƒ", 'kia', 'hyundai']
        selected_brand = st.selectbox("ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", brand, key="brand_select")
        
        if selected_brand != "ë¸Œëœë“œ ì„ íƒ":
            st.markdown("### ğŸš™ ì°¨ì¢… ì„ íƒ")
            models = list(car_data[selected_brand].keys())
            
            model_input = st.text_input(
                "ì°¨ì¢…ì„ ì…ë ¥í•˜ì„¸ìš” (ìë™ì™„ì„±)", 
                placeholder=f"ì˜ˆ: {', '.join(models[:2])}", 
                key="model_input"
            )
            
            if model_input:
                filtered_models = [model for model in models if model_input.lower() in model.lower()]
                if filtered_models:
                    selected_model = st.selectbox("ë§¤ì¹­ë˜ëŠ” ì°¨ì¢…", filtered_models, key="model_select")
                else:
                    st.warning("âš ï¸ ë§¤ì¹­ë˜ëŠ” ì°¨ì¢…ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ëª©ë¡ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    selected_model = st.selectbox("ì „ì²´ ì°¨ì¢… ëª©ë¡", ["ì°¨ì¢… ì„ íƒ"] + models, key="model_select_all")
                    if selected_model == "ì°¨ì¢… ì„ íƒ":
                        selected_model = None
            else:
                selected_model = st.selectbox("ì°¨ì¢…ì„ ì„ íƒí•˜ì„¸ìš”", ["ì°¨ì¢… ì„ íƒ"] + models, key="model_select_default")
                if selected_model == "ì°¨ì¢… ì„ íƒ":
                    selected_model = None
        else:
            selected_model = None
    
    with col2:
        if selected_brand != "ë¸Œëœë“œ ì„ íƒ":
            if selected_model:
                engines = car_data[selected_brand][selected_model]["engines"]
                
                st.markdown("### âš™ï¸ ì—”ì§„ íƒ€ì…")
                selected_engine = st.selectbox("ì—”ì§„ì„ ì„ íƒí•˜ì„¸ìš”", ["ì—”ì§„ ì„ íƒ"] + engines, key="engine_select")
                if selected_engine == "ì—”ì§„ ì„ íƒ":
                    selected_engine = None
            else:
                st.info("ğŸ“ ì°¨ì¢…ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”")
                selected_engine = None
        else:
            st.info("ğŸ“ ë¸Œëœë“œë¥¼ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”")
            selected_engine = None
    
    st.markdown("---")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ” ì§„ë‹¨ ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
            if selected_brand != "ë¸Œëœë“œ ì„ íƒ":
                st.session_state.car_info = {"ë¸Œëœë“œ": selected_brand or "ë¯¸ì§€ì •", "ì°¨ì¢…": selected_model or "ë¯¸ì§€ì •", "ì—”ì§„": selected_engine or "ë¯¸ì§€ì •"}
                st.session_state.page = 'chat'
                st.rerun()
            else:
                st.error("âŒ ìµœì†Œí•œ ë¸Œëœë“œëŠ” ì„ íƒí•´ì£¼ì„¸ìš”!")


# ì±„íŒ… í˜ì´ì§€
def chat_page(chain, vector_store):
    car_info = st.session_state.car_info

    st.markdown(f"""
    <div class="header-container">
        <h1>ğŸ”§ AutoFix AI ì§„ë‹¨ìƒë‹´</h1>
        <div class="car-info-box">
            ğŸš— {car_info['ì°¨ì¢…']} 
            âš™ï¸ {car_info['ì—”ì§„']}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.chat_history:
        st.markdown("### ğŸ’¬ ìƒë‹´ ë‚´ì—­")
        for message in st.session_state.chat_history:
            if message["type"] == "user":
                st.markdown(f'<div class="chat-message user-message">ğŸ‘¤ <strong>ê³ ê°:</strong><br>{message["content"]}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="chat-message bot-message">ğŸ¤– <strong>AI ì§„ë‹¨ì‚¬:</strong><br>{message["content"]}</div>', unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="chat-message bot-message">
            ğŸ¤– <strong>AI ì§„ë‹¨ì‚¬:</strong><br>
            ì•ˆë…•í•˜ì„¸ìš”! AutoFix AI ì§„ë‹¨ì„¼í„°ì…ë‹ˆë‹¤.<br>
            ì°¨ëŸ‰ì˜ ì¦ìƒì´ë‚˜ ë¬¸ì œì ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹œë©´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ì§„ë‹¨ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.<br><br>
            <strong>ì˜ˆì‹œ:</strong><br>
            â€¢ "ì‹œë™ ê±¸ ë•Œ ì—”ì§„ì—ì„œ ëœëœê±°ë¦¬ëŠ” ì†Œë¦¬ê°€ ë‚˜ìš”"<br>
            â€¢ "ê°€ì†í•  ë•Œ ì°¨ê°€ ë–¨ë ¤ìš”"<br>
            â€¢ "ì—”ì§„ ê²½ê³ ë“±ì´ ì¼œì¡Œì–´ìš”"<br>
            â€¢ "P0171 ì˜¤ë¥˜ ì½”ë“œê°€ ë‚˜ì™”ì–´ìš”"
        </div>
        """, unsafe_allow_html=True)
    
    # âœ… ì±„íŒ… ì…ë ¥ (ì—”í„° ì „ì†¡ + ìë™ ì´ˆê¸°í™”)
    if prompt := st.chat_input("ì°¨ëŸ‰ì˜ ì¦ìƒì´ë‚˜ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.chat_history.append({
            "type": "user",
            "content": prompt,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })

        with st.spinner("ğŸ¤– AIê°€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì§„ë‹¨í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            response = perform_rag_diagnosis(prompt, chain, vector_store, car_info)

        st.session_state.chat_history.append({
            "type": "bot",
            "content": response,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })

        st.rerun()
    
    with st.sidebar:
        st.markdown("### ğŸš— ë“±ë¡ ì°¨ëŸ‰")
        st.info(f"""
        **ì°¨ì¢…:** {car_info['ì°¨ì¢…']}  
        **ì—”ì§„:** {car_info['ì—”ì§„']}  
        """)
        
        if st.button("ğŸ”„ ì°¨ëŸ‰ ë³€ê²½í•˜ê¸°"):
            st.session_state.page = 'setup'
            st.session_state.chat_history = []
            st.cache_resource.clear()
            st.rerun()
            
        st.markdown("---")
        st.markdown("### ğŸ“Š ì§„ë‹¨ ì •ë³´")
        st.success("""
        âœ… **RAG ê¸°ë°˜ ì§„ë‹¨**  
        â€¢ ì‹¤ì‹œê°„ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰  
        â€¢ ì°¨ëŸ‰ë³„ ë§ì¶¤ ì§„ë‹¨  
        â€¢ ê³ ì¥ ì›ì¸ ë¶„ì„  
        â€¢ GSW ì˜¤ë¥˜ ì½”ë“œ í•´ì„   
        â€¢ ì •ë¹„ ê°€ì´ë“œ ì œê³µ  
        """)
        
        st.markdown("---")
        st.markdown("### ğŸ“ ì‘ê¸‰ì—°ë½ì²˜")
        st.error("""
        ğŸš¨ **ì‘ê¸‰ìƒí™©**  
        â€¢ í™”ì¬/ì‚¬ê³  : 119  
        â€¢ í•œêµ­ë„ë¡œê³µì‚¬: 1588-2504  
        â€¢ ê¸°ì•„ ê¸´ê¸‰ì¶œë™: 080-200-2000  
        â€¢ í˜„ëŒ€ ê¸´ê¸‰ì¶œë™: 080-600-6000
        """)
        
        if st.session_state.chat_history:
            st.markdown("---")
            if st.button("ğŸ—‘ï¸ ëŒ€í™”ë‚´ì—­ ì‚­ì œ"):
                st.session_state.chat_history = []
                if 'user' in store:
                    store['user'].clear()
                st.rerun()


# RAG ì§„ë‹¨ ìˆ˜í–‰
def perform_rag_diagnosis(query, chain, vector_store, car_info):
    main_filter, sub_filter = make_filter(car_info)
    
    if main_filter:
        main_docs = vector_store.similarity_search(query, k=1, filter=main_filter)
        unique_main_docs = list({doc.page_content: doc for doc in main_docs}.values())
    else:
        unique_main_docs = []
    
    sub_docs = vector_store.similarity_search(query, k=1)
    unique_sub_docs = list({doc.page_content: doc for doc in sub_docs}.values())
    all_docs = unique_main_docs + unique_sub_docs

    context_text = '\n'.join([doc.page_content for doc in all_docs])
    response = chain.invoke({'query': query, 'content': context_text}, config={'configurable': {'session_id': 'user'}})

    return response


# ë©”ì¸ ì‹¤í–‰
def main():
    initialize_session_state()
    vector_store, chain = initialize_rag_system()
    
    st.session_state["CAR_DATA"] = extract_car_data_from_db(vector_store)
    car_data = st.session_state.get("CAR_DATA")

    if st.session_state.page == 'setup':
        setup_page(car_data)
    elif st.session_state.page == 'chat':
        chat_page(chain, vector_store)

if __name__ == "__main__":
    main()